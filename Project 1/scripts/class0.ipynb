{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46f216d-f7cd-49d5-b2df-48d0157a7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from losses import *\n",
    "from EDA import *\n",
    "from plots import *\n",
    "from cross_validation import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4706bc-a4fe-404c-9a6a-1b1cd788a3ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Graphical exploration\n",
    "\n",
    "#### Load the training data into feature matrix, class labels, and event ids\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42c6ced-0a10-4b65-9533-6c503f2f6a3a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the tarin data set\n",
    "DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "data_y, data_set, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "# Classification of the output\n",
    "y_0, y_1, y_2, y_3 = y_classification(data_y, data_set)\n",
    "\n",
    "# EDA for each class\n",
    "class_0, class_1, class_2, class_3 = EDA_class(data_set, exploratory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de7e1a-b79f-4645-9df4-4ee6c2be1ca3",
   "metadata": {},
   "source": [
    "## Correlation matrix\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45e580-b8b6-4942-ba9c-50cfbd0cdadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_plot(class_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f155777a-a2f7-484e-8ee3-f3c3c8ebfe5a",
   "metadata": {},
   "source": [
    "**Remark:** There is no particular correlation to notice betweeen the different features of the class 0.\n",
    "\n",
    "## Histograms\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96660c0-2eb2-4452-8229-3841bbfa027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if some feature seems to be useless in this classification\n",
    "histogram_plot(y_0, class_0, [0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fcba1c-4c90-4bec-a248-1dd5e5a2941a",
   "metadata": {},
   "source": [
    "**Remark:**  We can notice that the feature 0 seems to very decisive in the classification, but it is not the case for the feature 2. Then, we can remove this last without losing information for our classification.\n",
    "We apply this idea to all the features and we obtain the following list of the features that we can remove: [2, 5, 8, 11, 13, 14]. For seeing the histograms of all the features, you just have to run the following piece of code in a cell: 'histogram_plot(y_0, class_0, [0, 2])'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74346c5",
   "metadata": {},
   "source": [
    "# Cross validation\n",
    "\n",
    "Now, the graphical analysis is done, we can use cross validation to select our best model (with its corresponding method).\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310429ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification of the output\n",
    "y_0, y_1, y_2, y_3 = y_classification(data_y, data_set, sub_sample=True)\n",
    "# Apply the exploratory graphical analysis\n",
    "class_0, class_1, class_2, class_3 = EDA_class(data_set, exploratory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a819201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization of some parameters\n",
    "max_degree = 6\n",
    "mse = MSE()\n",
    "neg_log = Neg_log()\n",
    "kfold = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903fb11",
   "metadata": {},
   "source": [
    "#### Least squares method\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8da154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters initialization\n",
    "param_least = Parameters()\n",
    "param_least.set_degree(max_degree)\n",
    "param_least.set_method(least_squares_)\n",
    "param_least.set_k_fold(kfold)\n",
    "param_least.set_viz(False)\n",
    "param_least.set_use_backward_selection(True)\n",
    "param_least.set_use_interactions(True)\n",
    "\n",
    "# Cross validation\n",
    "param_least = cross_validation_poly(y_0, class_0, param_least)\n",
    "\n",
    "\n",
    "print(\"Best train error: \", param_least.best_train_error)\n",
    "print(\"Best test error: \", param_least.best_error)\n",
    "print('Std: ', param_least.std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a822d3",
   "metadata": {},
   "source": [
    "#### Gradient descent method\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters initialization\n",
    "param_GD = Parameters()\n",
    "param_GD.set_degree(max_degree)\n",
    "param_GD.set_loss_fct(mse)\n",
    "param_GD.set_k_fold(kfold)\n",
    "param_GD.set_method(least_squares_GD_)\n",
    "param_GD.set_to_test(['gamma'])\n",
    "param_GD.set_viz(False)\n",
    "param_GD.set_use_backward_selection(True)\n",
    "param_GD.set_use_interactions(True)\n",
    "\n",
    "# Cross validation\n",
    "param_GD = cross_validation_poly(y_0, class_0, param_GD)\n",
    "\n",
    "print(\"Best train error: \", param_GD.best_train_error)\n",
    "print(\"Best test error: \", param_GD.best_error)\n",
    "print('Std: ', param_GD.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0f944f",
   "metadata": {},
   "source": [
    "#### Stochastic gradient descent\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters initialization\n",
    "param_SGD = Parameters()\n",
    "param_SGD.set_degree(max_degree)\n",
    "param_SGD.set_k_fold(kfold)\n",
    "param_SGD.set_loss_fct(mse)\n",
    "param_SGD.set_method(least_squares_SGD_)\n",
    "param_SGD.set_to_test(['gamma'])\n",
    "param_SGD.set_viz(False)\n",
    "param_SGD.set_use_backward_selection(True)\n",
    "param_SGD.set_use_interactions(True)\n",
    "\n",
    "# Cross validation\n",
    "param_SGD = cross_validation_poly(y_0, class_0, param_SGD)\n",
    "\n",
    "print(\"Best train error: \", param_SGD.best_train_error)\n",
    "print(\"Best test error: \", param_SGD.best_error)\n",
    "print('Std: ', param_SGD.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8288f303",
   "metadata": {},
   "source": [
    "#### Ridge regression\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters initialization\n",
    "param_ridge = Parameters()\n",
    "param_ridge.set_degree(max_degree)\n",
    "param_ridge.set_loss_fct(mse)\n",
    "param_ridge.set_k_fold(kfold)\n",
    "param_ridge.set_method(ridge_regression_)\n",
    "param_ridge.set_to_test(['lambda'])\n",
    "param_ridge.set_viz(False)\n",
    "param_ridge.set_use_backward_selection(True)\n",
    "param_ridge.set_use_interactions(True)\n",
    "\n",
    "# Cross validation\n",
    "param_ridge = cross_validation_poly(y_0, class_0, param_ridge)\n",
    "\n",
    "print(\"Best train error: \", param_ridge.best_train_error)\n",
    "print(\"Best test error: \", param_ridge.best_error)\n",
    "print('Std: ', param_ridge.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04087065",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a39a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parmeters initialization\n",
    "param_log = Parameters()\n",
    "param_log.set_degree(max_degree)\n",
    "param_log.set_loss_fct(mse)\n",
    "param_log.set_k_fold(kfold)\n",
    "param_log.set_method(logistic_regression_)\n",
    "param_log.set_to_test(['gamma'])\n",
    "param_log.set_viz(False)\n",
    "param_log.set_use_backward_selection(True)\n",
    "param_log.set_use_interactions(True)\n",
    "\n",
    "# Cross validation\n",
    "param_log = cross_validation_poly(y_0, class_0, param_log)\n",
    "\n",
    "print(\"Best train error: \", param_log.best_train_error)\n",
    "print(\"Best test error: \", param_log.best_error)\n",
    "print('Std: ', param_log.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74937d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_cv(y_, class_, parameters, idx):\n",
    "    seed = parameters.seeds[0]\n",
    "\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y_, parameters.k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    error_te = []\n",
    "    error_tr = []\n",
    "\n",
    "    for param in parameters.range(idx):\n",
    "        parameters.set_param(idx, param)\n",
    "        error_tr_i = [-1]\n",
    "        error_te_i = [-1]\n",
    "\n",
    "        for k in range(parameters.k_fold):\n",
    "            # cross validation:\n",
    "            percentage_error_tr, percentage_error_te = \\\n",
    "                method_evaluation(y_, class_, parameters, k_indices, k)\n",
    "            error_tr_i = np.c_[error_tr_i, [percentage_error_tr]]\n",
    "            error_te_i = np.c_[error_te_i, [percentage_error_te]]\n",
    "\n",
    "        error_tr.append(np.mean(error_tr_i[0, 1:]))\n",
    "        error_te.append(np.mean(error_te_i[0, 1:]))\n",
    "\n",
    "    best_param = parameters.range(idx)[np.argmin(error_te)]\n",
    "    parameters.set_best_param(idx, best_param)\n",
    "    parameters.set_param(idx, best_param)\n",
    "    parameters.set_best_error(np.min(error_te))\n",
    "\n",
    "    # Display the results\n",
    "    min_test_error = np.min(error_te)\n",
    "    if parameters.viz:\n",
    "        print('Test error: ' +str(min_test_error)+ '\\nBest ' \\\n",
    "            +str(parameters.names[idx-1])+ ': ' +str(parameters.best_param(idx)))\n",
    "\n",
    "    # Visualization\n",
    "    if parameters.viz:\n",
    "        cross_validation_visualization(parameters.range(idx), error_tr, error_te, parameters)\n",
    "    \n",
    "    return parameters"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56182d08d34034e89fc2125c3a19af52ba9d106be31d6a17441e7856e867a350"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
