{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from EDA import *\n",
    "from losses import *\n",
    "from crossvalidation import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "y, data_set, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the seed\n",
    "seed = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''boxplot of some features to get an idea of the distribution'''\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.boxplot(data_set[:,0])\n",
    "plt.show()\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.boxplot(data_set[:,1])\n",
    "plt.show()\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.boxplot(data_set[:,2])\n",
    "plt.show()\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.boxplot(data_set[:,3])\n",
    "plt.show()\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.boxplot(data_set[:,4])\n",
    "plt.show()\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.boxplot(data_set[:,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_y_neg = np.array(np.where(y == -1)[0])\n",
    "ind_y_pos = np.array(np.where(y == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# histogram of some features\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.hist(data_set[ind_y_neg,0], histtype = 'step', color = 'red')\n",
    "plt.hist(data_set[ind_y_pos,0], histtype = 'step')\n",
    "plt.title('Histogram of feature 0')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.hist(data_set[ind_y_neg,1], histtype = 'step', color = 'red')\n",
    "plt.hist(data_set[ind_y_pos,1], histtype = 'step')\n",
    "plt.title('Histogram of feature 1')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.hist(data_set[ind_y_neg,2], histtype = 'step', color = 'red')\n",
    "plt.hist(data_set[ind_y_pos,2], histtype = 'step')\n",
    "plt.title('Histogram of feature 2')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.hist(data_set[ind_y_neg,3], histtype = 'step', color = 'red')\n",
    "plt.hist(data_set[ind_y_pos,3], histtype = 'step')\n",
    "plt.title('Histogram of feature 3')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.hist(data_set[ind_y_neg,4], histtype = 'step', color = 'red')\n",
    "plt.hist(data_set[ind_y_pos,4], histtype = 'step')\n",
    "plt.title('Histogram of feature 4')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.hist(data_set[ind_y_neg,5], histtype = 'step', color = 'red')\n",
    "plt.hist(data_set[ind_y_pos,5], histtype = 'step')\n",
    "plt.title('Histogram of feature 5')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these histograms, we see that some features have constinuous distribution while others have discrete distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Counting the number of outliers for each feature\n",
    "out = []\n",
    "for i in range (data_set.shape[1]):\n",
    "    ind = indices_outliers(data_set[:,i])\n",
    "    out.append(len(ind))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting a scatter plot\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.scatter(data_set[:,0], data_set[:,1])\n",
    "ax.set_xlabel('feature 1')\n",
    "ax.set_ylabel('feature 2')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.scatter(data_set[:,4], data_set[:,5])\n",
    "ax.set_xlabel('feature 5')\n",
    "ax.set_ylabel('feature 6')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and classify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification of the output\n",
    "y_0, y_1, y_2, y_3 = y_classification(y, data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA for each class\n",
    "class_0, class_1, class_2, class_3 = EDA_class(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the \"spliter\" value correponding to the part dedicated for train\n",
    "spliter = 0.8\n",
    "\n",
    "# Split into a train and a test set\n",
    "train_0, y_tr_0, test_0, y_te_0 = train_test_separator(y_0, class_0, spliter, seed)\n",
    "train_1, y_tr_1, test_1, y_te_1 = train_test_separator(y_1, class_1, spliter, seed)\n",
    "train_2, y_tr_2, test_2, y_te_2 = train_test_separator(y_2, class_2, spliter, seed)\n",
    "train_3, y_tr_3, test_3, y_te_3 = train_test_separator(y_3, class_3, spliter, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fitting class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_loss = MSE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, w_least_squares = least_squares(y_tr_0, train_0, MSE_loss)\n",
    "print(\"train mse: \" + str(mse))\n",
    "\n",
    "train_pred = predict_labels(w_least_squares, train_0)\n",
    "counting_errors(train_pred, y_tr_0)\n",
    "\n",
    "test_pred = predict_labels(w_least_squares, test_0)\n",
    "counting_errors(test_pred, y_te_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Least Squares Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones(train_0.shape[1])\n",
    "mse, w_least_squares_GD = least_squares_GD(y_tr_0, train_0, MSE_loss, initial_w, max_iters = 1000, gamma = 0.000001)\n",
    "print(\"train mse: \" + str(mse))\n",
    "\n",
    "train_pred = predict_labels(w_least_squares_GD, train_0)\n",
    "counting_errors(train_pred, y_tr_0)\n",
    "\n",
    "test_pred = predict_labels(w_least_squares_GD, test_0)\n",
    "counting_errors(test_pred, y_te_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_w = np.ones(train_0.shape[1])\n",
    "mse, w_least_squares_SGD = least_squares_SGD(y_tr_0, train_0, MSE_loss, initial_w, max_iters = 1000, gamma = 0.001, mini_batch_size=100)\n",
    "print(\"train mse: \" + str(mse))\n",
    "\n",
    "train_pred = predict_labels(w_least_squares_SGD, train_0)\n",
    "counting_errors(train_pred, y_tr_0)\n",
    "\n",
    "test_pred = predict_labels(w_least_squares_SGD, test_0)\n",
    "counting_errors(test_pred, y_te_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, w_ridge_regression = ridge_regression(y_tr_0, train_0, MSE_loss, 0.000000001)\n",
    "print(\"train mse: \" + str(mse))\n",
    "\n",
    "train_pred = predict_labels(w_ridge_regression, class_0)\n",
    "counting_errors(train_pred, y_0)\n",
    "\n",
    "test_pred = predict_labels(w_ridge_regression, test_0)\n",
    "counting_errors(test_pred, y_te_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_log = Neg_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the -1 output by 0 because our logistic regression is for y = {0, 1}\n",
    "ind_y_tr_0_neg = np.array(np.where(y_tr_0 == -1)[0])\n",
    "ind_y_te_0_neg = np.array(np.where(y_te_0 == -1)[0])\n",
    "for i in (ind_y_tr_0_neg):\n",
    "    y_tr_0[i] = 0\n",
    "for i in (ind_y_te_0_neg):\n",
    "    y_te_0[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(train_0.shape[1])\n",
    "mse, w_log_reg_GD = logistic_regression(y_tr_0, train_0, neg_log, initial_w)\n",
    "print(\"train mse: \" + str(mse))\n",
    "\n",
    "train_pred = predict_labels(w_log_reg_GD, train_0)\n",
    "counting_errors(train_pred, y_tr_0)\n",
    "\n",
    "test_pred = predict_labels(w_log_reg_GD, test_0)\n",
    "counting_errors(test_pred, y_te_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_loss = MSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas_ = np.logspace(-6, -1, 30)\n",
    "cross_validation_plot(y_0, class_0, MSE_loss, ridge_regression, lambdas_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation fonctionne pour une seule step avec ridge mais dès que je la mets comme method dans le code du dessus ça ne fonctionne pas. Je ne comprends pas pourquoi. \n",
    "##### Aussi je ne suis pas sûre de quel set utiliser: train_0 ou class_0? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### seed = 1\n",
    "k_fold = 4\n",
    "method = ridge_regression\n",
    "k = 2\n",
    "initial_w = np.zeros(class_0.shape[1])\n",
    "# split data in k fold\n",
    "k_indices = build_k_indices(y_0, k_fold, seed)\n",
    "loss_tr, loss_te = cross_validation(y_0, class_0, k_indices, k, method, initial_w) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fitting class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, w_least_squares = least_squares(train_truth, train_set)\n",
    "print(\"train mse: \" + str(mse))\n",
    "\n",
    "train_pred = predict_labels(w_least_squares, train_set)\n",
    "counting_errors(train_pred, train_truth)\n",
    "\n",
    "test_pred = predict_labels(w_least_squares, test_set)\n",
    "counting_errors(test_pred, test_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Least Squares Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.ones(train_set.shape[1])\n",
    "mse, w_least_squares_GD = least_squares_GD(train_truth, train_set, initial_w, max_iters = 100, gamma = 0.000001)\n",
    "print(\"train mse: \" + str(mse))\n",
    "\n",
    "train_pred = predict_labels(w_least_squares_GD, train_set)\n",
    "counting_errors(train_pred, train_truth)\n",
    "\n",
    "test_pred = predict_labels(w_least_squares_GD, test_set)\n",
    "counting_errors(test_pred, test_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_w = np.ones(train_set.shape[1])\n",
    "mse, w_least_squares_SGD = stochastic_gradient_descent(train_truth, train_set, initial_w, max_iters = 50, gamma = 0.001, batch_size=100)\n",
    "print(\"train mse: \" + str(mse))\n",
    "\n",
    "train_pred = predict_labels(w_least_squares_SGD, train_set)\n",
    "counting_errors(train_pred, train_truth)\n",
    "\n",
    "test_pred = predict_labels(w_least_squares_SGD, test_set)\n",
    "counting_errors(test_pred, test_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, w_least_squares_SGD = ridge_regression(train_truth, train_set, 0.001)\n",
    "print(\"train mse: \" + str(mse))\n",
    "\n",
    "train_pred = predict_labels(w_least_squares_SGD, train_set)\n",
    "counting_errors(train_pred, train_truth)\n",
    "\n",
    "test_pred = predict_labels(w_least_squares_SGD, test_set)\n",
    "counting_errors(test_pred, test_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.zeros(train_set.shape[1])\n",
    "mse, w_log_reg_GD = logistic_regression_GD(train_truth, train_set, initial_w, 0.01, 100)\n",
    "print(\"train mse: \" + str(mse))\n",
    "\n",
    "train_pred = predict_labels(w_log_reg_GD, train_set)\n",
    "counting_errors(train_pred, train_truth)\n",
    "\n",
    "test_pred = predict_labels(w_log_reg_GD, test_set)\n",
    "counting_errors(test_pred, test_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "k = 2\n",
    "k_indices = build_k_indices(train_truth, k_fold, seed)\n",
    "initial_w = np.zeros(train_set.shape[1])\n",
    "loss_tr, loss_te = cross_validation(train_truth, train_set, k_indices, k, least_squares_GD, initial_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training loss : ' + str(loss_tr))\n",
    "print('testing loss : ' + str(loss_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"../data/test.csv\"\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_.shape, tX_test.shape, ids_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''choose the w we want to use for the submission and the tX_test'''\n",
    "weights = w_least_squares_GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/sample-submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "interpreter": {
   "hash": "ab6a13f8d35690fc54a0784a7c413b5c6b88c02b498e2bc6bdd4734947920c66"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
