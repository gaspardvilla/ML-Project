{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MSCDB api\n",
    "import mascdb.api\n",
    "from mascdb.api import MASC_DB\n",
    "\n",
    "# Import other libraries\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import sklearn tools\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Import files\n",
    "from helpers import *\n",
    "\n",
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masc_path = 'Data/MASCDB'\n",
    "mascdb_features = MASC_DB(masc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mascdb_features)\n",
    "len(mascdb_features)\n",
    "mascdb_features.cam0.sns.boxplot(x = \"Dmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Par exemple, on peut avoir 1100 flocons qui sont classifiés pour la cam 2, mais seulement 815 sont dans le parquet file. La raison veint du fait que la classification a été faite sur les images et donc les données numériques n'ont pas été nécéssairement produites poru toutes les photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns to delelte for our experiences\n",
    "black_list_words = ['roi', 'riming', 'melting', 'snowflake', 'hl']\n",
    "cols_to_delete = list(filter(lambda cols: any(word in cols for word in black_list_words), mascdb_features.cam0.columns))\n",
    "cols_to_delete.extend(['datetime', 'pix_size', 'flake_number_tmp', 'event_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascdb_features_filt = mascdb_features.drop_cam_columns(cols_to_delete)\n",
    "display(mascdb_features_filt.cam0.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Normal d'avoir deux fois la colonne `flake_id` dans notre dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train set\n",
    "mascdb_classes = MASCDB_classes(\"Data\")\n",
    "cam0_train_set = mascdb_classes.get_sub_data_cam(\"hydro\", 0, mascdb_features.cam0)\n",
    "display(mascdb_classes.hydro_cam0.head(10))\n",
    "for i in range(1, 7):\n",
    "    display(mascdb_classes.hydro_cam0[mascdb_classes.hydro_cam0.class_id == i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization of the data\n",
    "classified_data = mascdb_classes.get_classified_data(\"hydro\", mascdb_features_filt)\n",
    "pt = preprocessing.PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "classified_data_ = pt.fit(classified_data.drop(['flake_id'], axis=1))\n",
    "classified_data_ = pt.transform(classified_data.drop(['flake_id'], axis=1))\n",
    "display(classified_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data[classified_data.columns.difference(['flake_id'])]  = classified_data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = mascdb_classes.get_classses(\"hydro\", mascdb_features_filt)\n",
    "display(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just a small test\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea is just to have a brut test / train separator\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    classified_data[classified_data.columns.difference(['flake_id'])], classes[classes.columns.difference(['flake_id'])], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection test\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The idea is just to have a brut test / train separator\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    classified_data[classified_data.columns.difference(['flake_id'])], classes[classes.columns.difference(['flake_id'])], test_size=0.33, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selec = features_selection(X_train, y_train, 'recursiveCV', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_selec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_recursive = features_selection(X_train, y_train, 'recursive', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_recursive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lasso = features_selection(X_train, y_train, 'lasso', 0.1, True)\n",
    "display(X_lasso.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird: when param >= 2 for method = 'lasso', all the features are putted to zero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lassoCV = features_selection(X_train, y_train, 'lassoCV', 4, True)\n",
    "display(X_lassoCV.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_PCA = features_selection(X_train, y_train, 'PCA', 10, True)\n",
    "print(X_PCA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
