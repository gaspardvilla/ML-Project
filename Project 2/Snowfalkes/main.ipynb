{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MSCDB api\n",
    "import mascdb.api\n",
    "from mascdb.api import MASC_DB\n",
    "\n",
    "# Import other libraries\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "\n",
    "# Import sklearn tools\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.preprocessing import * \n",
    "\n",
    "# Import files\n",
    "from helpers import *\n",
    "from cross_validation import *\n",
    "from models import *\n",
    "\n",
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masc_path = 'Data/MASCDB'\n",
    "mascdb_features = MASC_DB(masc_path)\n",
    "\n",
    "# Get train set\n",
    "Mascdb_classes = MASCDB_classes(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the columns to delete for our experiences\n",
    "black_list_words = ['roi', 'riming', 'melting', 'snowflake', 'hl']\n",
    "cols_to_delete = list(filter(lambda cols: any(word in cols for word in black_list_words), mascdb_features.cam0.columns))\n",
    "cols_to_delete.extend(['datetime', 'pix_size', 'flake_number_tmp', 'event_id'])\n",
    "mascdb_features_filt = mascdb_features.drop_cam_columns(cols_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop duplicates\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the classifier\n",
    "classifier  = 'hydro'\n",
    "\n",
    "# Get the data and the correpsonding classes\n",
    "mascdb_data = Mascdb_classes.get_classified_data('hydro', mascdb_features_filt)\n",
    "mascdb_classes = Mascdb_classes.get_classes('hydro', mascdb_features_filt)\n",
    "\n",
    "display(mascdb_data)\n",
    "display(mascdb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the wrong duplicates flakes\n",
    "mascdb_classes_copy = mascdb_classes.copy()\n",
    "\n",
    "mascdb_classes_copy_1 = mascdb_classes_copy[mascdb_classes_copy.duplicated(subset = None, keep = False)]\n",
    "mascdb_classes_copy_2 = mascdb_classes_copy[mascdb_classes_copy.duplicated(subset=['flake_id'], keep = False)]\n",
    "\n",
    "mascdb_classes_wrong_duplicates = pd.concat([mascdb_classes_copy_1, mascdb_classes_copy_2]).drop_duplicates(keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the flake id of the wrong duplicates\n",
    "mascdb_classes_wrong_duplicates_unique = mascdb_classes_wrong_duplicates.drop_duplicates(subset = ['flake_id'], keep = 'first')\n",
    "\n",
    "# Get all the flake id with classes\n",
    "flake_id_classes = mascdb_classes_copy.drop_duplicates(subset=['flake_id'], keep = 'first')\n",
    "\n",
    "# Remove the wrong flake id from all the flake id\n",
    "mascdb_classes_modified = pd.concat([flake_id_classes, mascdb_classes_wrong_duplicates_unique]).drop_duplicates(subset=['flake_id'], keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we want to be sure to have one class for each snowflakes\n",
    "mascdb_data_modified = mascdb_data[mascdb_data.flake_id.isin(mascdb_classes_modified.flake_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform the data (standardization)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "mascdb_data_modified_copy = mascdb_data_modified.copy()\n",
    "power_transformer = preprocessing.PowerTransformer(method = 'yeo-johnson', standardize = True)\n",
    "mascdb_data_modified_std = power_transformer.fit(mascdb_data_modified_copy.drop(['flake_id'], axis=1))\n",
    "mascdb_data_modified_std = power_transformer.transform(mascdb_data_modified_copy.drop(['flake_id'], axis=1))\n",
    "\n",
    "# Set the transformed data\n",
    "mascdb_data_modified[mascdb_data_modified.columns.difference(['flake_id'])]  = mascdb_data_modified_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelization\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into a data set X_ and a response set y_\n",
    "X_ = mascdb_data_modified[mascdb_data_modified.columns.difference(['flake_id'])]\n",
    "y_ = mascdb_classes_modified.copy().set_index('flake_id')\n",
    "\n",
    "# Get a column as flake_id\n",
    "X_['flake_id'] = X_.index\n",
    "\n",
    "# Supress all the duplicates flake_id and get the correponding class\n",
    "X_ = X_.drop_duplicates(subset = 'flake_id', keep = 'first').join(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into a data set X and a response set y\n",
    "y = pd.DataFrame(X_['class_id'])\n",
    "X = X_[X_.columns.difference(['flake_id', 'class_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a train and test set for modelization\n",
    "X_train, y_train, X_test, y_test = split_data(X, y, n_s = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
